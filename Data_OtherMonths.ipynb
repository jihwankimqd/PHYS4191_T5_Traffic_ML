{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the individual csv files for each hour into individual dataframes.\n",
    "\n",
    "# Change the \"./March_dd_CSV\" to generalize to different dates.\n",
    "Date = \"27\"\n",
    "March_Date = \"202002\"+str(Date)\n",
    "March_Directory = \"./M06A_Feb_\"+str(Date)+\"/\"+str(March_Date)\n",
    "\n",
    "# Similarly, change \"yyyymmdd\" to generalize to different dates.\n",
    "\n",
    "# Format: March_00 ==> March_hh.\n",
    "\n",
    "March_00 = pd.read_csv(str(March_Directory)+\"/00/TDCS_M06A_\"+str(March_Date)+\"_000000.csv\")\n",
    "March_00 = March_00.T.reset_index(drop=True).T\n",
    "\n",
    "March_01 = pd.read_csv(str(March_Directory)+\"/01/TDCS_M06A_\"+str(March_Date)+\"_010000.csv\")\n",
    "March_01 = March_01.T.reset_index(drop=True).T\n",
    "\n",
    "March_02 = pd.read_csv(str(March_Directory)+\"/02/TDCS_M06A_\"+str(March_Date)+\"_020000.csv\")\n",
    "March_02 = March_02.T.reset_index(drop=True).T\n",
    "\n",
    "March_03 = pd.read_csv(str(March_Directory)+\"/03/TDCS_M06A_\"+str(March_Date)+\"_030000.csv\")\n",
    "March_03 = March_03.T.reset_index(drop=True).T\n",
    "\n",
    "March_04 = pd.read_csv(str(March_Directory)+\"/04/TDCS_M06A_\"+str(March_Date)+\"_040000.csv\")\n",
    "March_04 = March_04.T.reset_index(drop=True).T\n",
    "\n",
    "March_05 = pd.read_csv(str(March_Directory)+\"/05/TDCS_M06A_\"+str(March_Date)+\"_050000.csv\")\n",
    "March_05 = March_05.T.reset_index(drop=True).T\n",
    "\n",
    "March_06 = pd.read_csv(str(March_Directory)+\"/06/TDCS_M06A_\"+str(March_Date)+\"_060000.csv\")\n",
    "March_06 = March_06.T.reset_index(drop=True).T\n",
    "\n",
    "March_07 = pd.read_csv(str(March_Directory)+\"/07/TDCS_M06A_\"+str(March_Date)+\"_070000.csv\")\n",
    "March_07 = March_07.T.reset_index(drop=True).T\n",
    "\n",
    "March_08 = pd.read_csv(str(March_Directory)+\"/08/TDCS_M06A_\"+str(March_Date)+\"_080000.csv\")\n",
    "March_08 = March_08.T.reset_index(drop=True).T\n",
    "\n",
    "March_09 = pd.read_csv(str(March_Directory)+\"/09/TDCS_M06A_\"+str(March_Date)+\"_090000.csv\")\n",
    "March_09 = March_09.T.reset_index(drop=True).T\n",
    "\n",
    "March_10 = pd.read_csv(str(March_Directory)+\"/10/TDCS_M06A_\"+str(March_Date)+\"_100000.csv\")\n",
    "March_10 = March_10.T.reset_index(drop=True).T\n",
    "\n",
    "March_11 = pd.read_csv(str(March_Directory)+\"/11/TDCS_M06A_\"+str(March_Date)+\"_110000.csv\")\n",
    "March_11 = March_11.T.reset_index(drop=True).T\n",
    "\n",
    "March_12 = pd.read_csv(str(March_Directory)+\"/12/TDCS_M06A_\"+str(March_Date)+\"_120000.csv\")\n",
    "March_12 = March_12.T.reset_index(drop=True).T\n",
    "\n",
    "March_13 = pd.read_csv(str(March_Directory)+\"/13/TDCS_M06A_\"+str(March_Date)+\"_130000.csv\")\n",
    "March_13 = March_13.T.reset_index(drop=True).T\n",
    "\n",
    "March_14 = pd.read_csv(str(March_Directory)+\"/14/TDCS_M06A_\"+str(March_Date)+\"_140000.csv\")\n",
    "March_14 = March_14.T.reset_index(drop=True).T\n",
    "\n",
    "March_15 = pd.read_csv(str(March_Directory)+\"/15/TDCS_M06A_\"+str(March_Date)+\"_150000.csv\")\n",
    "March_15 = March_15.T.reset_index(drop=True).T\n",
    "\n",
    "March_16 = pd.read_csv(str(March_Directory)+\"/16/TDCS_M06A_\"+str(March_Date)+\"_160000.csv\")\n",
    "March_16 = March_16.T.reset_index(drop=True).T\n",
    "\n",
    "March_17 = pd.read_csv(str(March_Directory)+\"/17/TDCS_M06A_\"+str(March_Date)+\"_170000.csv\")\n",
    "March_17 = March_17.T.reset_index(drop=True).T\n",
    "\n",
    "March_18 = pd.read_csv(str(March_Directory)+\"/18/TDCS_M06A_\"+str(March_Date)+\"_180000.csv\")\n",
    "March_18 = March_18.T.reset_index(drop=True).T\n",
    "\n",
    "March_19 = pd.read_csv(str(March_Directory)+\"/19/TDCS_M06A_\"+str(March_Date)+\"_190000.csv\")\n",
    "March_19 = March_19.T.reset_index(drop=True).T\n",
    "\n",
    "March_20 = pd.read_csv(str(March_Directory)+\"/20/TDCS_M06A_\"+str(March_Date)+\"_200000.csv\")\n",
    "March_20 = March_20.T.reset_index(drop=True).T\n",
    "\n",
    "March_21 = pd.read_csv(str(March_Directory)+\"/21/TDCS_M06A_\"+str(March_Date)+\"_210000.csv\")\n",
    "March_21 = March_21.T.reset_index(drop=True).T\n",
    "\n",
    "March_22 = pd.read_csv(str(March_Directory)+\"/22/TDCS_M06A_\"+str(March_Date)+\"_220000.csv\")\n",
    "March_22 = March_22.T.reset_index(drop=True).T\n",
    "\n",
    "March_23 = pd.read_csv(str(March_Directory)+\"/23/TDCS_M06A_\"+str(March_Date)+\"_230000.csv\")\n",
    "March_23 = March_23.T.reset_index(drop=True).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df represents the combined dataframe for the selected date.\n",
    "\n",
    "df = pd.concat([March_00,March_01, March_02, March_03, March_04, March_05, March_06, March_07, March_08, March_09, March_10, March_11, March_12, March_13, March_14, March_15, March_16, March_17, March_18, March_19, March_20, March_21, March_22, March_23], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3361232, 8)"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "# Check if the dataframe combined successfully.\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export as csv\n",
    "File_Name = 'Feb_'+str(Date)\n",
    "\n",
    "# Change File_Name 'March_dd' to generalize to different dates.\n",
    "df.to_csv(str(File_Name)+'_FullData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}